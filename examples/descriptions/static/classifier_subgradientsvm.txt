In this example a two-class linear support vector machine classifier is trained
on a toy data set and the trained classifier is then used to predict labels of
test examples. As training algorithm the steepest descent subgradient algorithm
is used. The SVM regularization parameter is set to C=1.2 and the solver
iterates until it either finds epsilon-precise solution or the maximal training
time max_train_time=60 is exceeded. The unbiased linear rule is trained.

Note that this solver often does not converges because the steepest descent
subgradient algorithm is oversensitive to rounding errors. Note also that this
is an unpublished work which was predecessor of the OCAS solver (see
classifier_svmocas).
