{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Neural Nets for Digit Classification"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Khaled Nasr (GitHub ID: khalednasr)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This notebook illustrates how to use the NeuralNets module to teach a neural network to recognize digits"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Introduction"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "An Artificial Neural Network is a machine learning model that is inspired by the way biological nervous systems, such as the brain, process information. The building block of neural networks is called a neuron. All a neuron does is take a weighted sum of its inputs and pass it through some non-linear function (activation function) to produce its output. A (feed-forward) neural network is a bunch of neurons arranged in layers, where each neuron in layer *i* takes its input from all the neurons in layer *i-1*. for more information on how neural networks work, [follow this link](https://www.youtube.com/playlist?list=PL6Xpj9I5qXYEcOhn7TqghAJ6NAPrNmUBH).\n",
      "\n",
      "In this notebook, we'll look at how a neural network can be used to recognize digits. We'll build a small neural network with one hidden layer and train it on the USPS dataset of handwritten digits.\n",
      "\n",
      "We'll start by loading the data and dividing it into a training set and a test set:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.io import loadmat\n",
      "from modshogun import RealFeatures, MulticlassLabels\n",
      "\n",
      "# load the dataset\n",
      "dataset = loadmat('../../../data/multiclass/usps.mat')\n",
      "\n",
      "Xall = dataset['data']\n",
      "# the usps dataset has the digits labeled from 1 to 10 \n",
      "# we'll subtract 1 to make them in the 0-9 range instead\n",
      "Yall = np.array(dataset['label'].squeeze(), dtype=np.double)-1 \n",
      "\n",
      "# use the first 5000 examples for training, the rest will be used for testing\n",
      "Xtrain = RealFeatures(Xall[:,0:5000])\n",
      "Ytrain = MulticlassLabels(Yall[0:5000])\n",
      "Xtest = RealFeatures(Xall[:,5001:-1])\n",
      "Ytest = MulticlassLabels(Yall[5001:-1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Creating the network"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To create a neural network in shogun, we'll first create an instance of [NeuralNetwork](http://www.shogun-toolbox.org/doc/en/latest/classshogun_1_1CNeuralNetwork.html) and then [initialize](http://www.shogun-toolbox.org/doc/en/latest/classshogun_1_1CNeuralNetwork.html#a8ff6d177c3e2d8977e5fc6920d3e1579) it by telling it how many inputs it has and what type of layers it contains. To specifiy the layers of the network a [DynamicObjectArray](http://www.shogun-toolbox.org/doc/en/latest/classshogun_1_1CDynamicObjectArray.html) is used. The array contains instances [NeuralLayer](http://www.shogun-toolbox.org/doc/en/latest/classshogun_1_1CNeuralLayer.html)-based classes that determine the type of neurons each layer consists of. Some of the layer types support are: [NeuralLinearLayer](http://www.shogun-toolbox.org/doc/en/latest/classshogun_1_1CNeuralLinearLayer.html), [NeuralLogisticLayer](http://www.shogun-toolbox.org/doc/en/latest/classshogun_1_1CNeuralLogisticLayer.html) and\n",
      "[NeuralSoftmaxLayer](http://www.shogun-toolbox.org/doc/en/latest/classshogun_1_1CNeuralSoftmaxLayer.html).\n",
      "\n",
      "For this notebook, we'll create a network with logistic hidden layer and a softmax output layer:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from modshogun import NeuralNetwork, NeuralLogisticLayer, NeuralSoftmaxLayer\n",
      "from modshogun import DynamicObjectArray\n",
      "\n",
      "# setup the network's layers\n",
      "layers = DynamicObjectArray()\n",
      "layers.append_element(NeuralLogisticLayer(50)) # 50 neurons in the hidden layer\n",
      "layers.append_element(NeuralSoftmaxLayer(10)) # 10 neurons in the output layer, on for each digit class\n",
      "\n",
      "# create the network\n",
      "net = NeuralNetwork()\n",
      "net.initialize(256, layers) # 256 inputs, one for each pixel (images in the dataset are 16*16 pixels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Training"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next, We'll train the network using the defualt settings (L-BFGS optimization). To see all the options available for training, check the [documentation](http://www.shogun-toolbox.org/doc/en/latest/classshogun_1_1CNeuralNetwork.html#pub-attribs). We'll also add some regularization to avoid overfitting:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "net.l2_coefficient = 0.001 # L2 regularization coefficient\n",
      "\n",
      "net.set_labels(Ytrain)\n",
      "net.train(Xtrain) # this might take a while, depending on your machine"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Evaluation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we'll evaluate the network using the test set:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from modshogun import MulticlassAccuracy\n",
      "\n",
      "# predict the labels of the test set\n",
      "predictions = net.apply_multiclass(Xtest)\n",
      "\n",
      "# compute accuracy\n",
      "evaluator = MulticlassAccuracy()\n",
      "accuracy = evaluator.evaluate(predictions, Ytest)\n",
      "print \"Accuracy on the test set =\", accuracy * 100"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can also look at some of the images and the network's response to each of them:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "_=figure(figsize=(17,6))\n",
      "gray()\n",
      "# plot 5 images, with the predicted label as the title of each image\n",
      "# this code is borrowed from the KNN notebook by Chiyuan Zhang and S\u00f6ren Sonnenburg \n",
      "for i in xrange(5):\n",
      "    ax=subplot(1,5,i+1)\n",
      "    title(int(predictions[i]))\n",
      "    ax.imshow(Xtest[:,i].reshape((16,16)), interpolation='nearest')\n",
      "    ax.set_xticks([])\n",
      "    ax.set_yticks([])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}